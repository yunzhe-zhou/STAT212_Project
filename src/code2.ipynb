{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code2.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1yk0ctFAOkGyA5iUwwdO6qNz5Wy2T1GBo","authorship_tag":"ABX9TyNuIZGOKISgOKu+3EooN13N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EZn4PoltQXRZ","executionInfo":{"status":"ok","timestamp":1617349607570,"user_tz":-480,"elapsed":859,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["import os\n","os.getcwd()\n","os.chdir(\"drive/My Drive/STAT212/DeepZip_code/src\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"HLQN9I10QavU","executionInfo":{"status":"ok","timestamp":1617351092446,"user_tz":-480,"elapsed":1585,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["from sklearn.metrics import mean_squared_error\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","import argparse\n","import contextlib\n","import arithmeticcoding_fast\n","import json\n","from tqdm import tqdm\n","import struct\n","import tempfile\n","import shutil\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import numpy as np\n","import torch.quantization\n","import zipfile\n","\n","# Device configuration\n","# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device = torch.device('cpu')\n","torch.manual_seed(1)\n","\n","parser = argparse.ArgumentParser(description='Input')\n","parser.add_argument('-model', action='store', dest='model_weights_file',\n","                    help='model file')\n","parser.add_argument('-model_name', action='store', dest='model_name',\n","                    help='model file')\n","parser.add_argument('-batch_size', action='store', dest='batch_size', type=int,\n","                    help='model file')\n","parser.add_argument('-data', action='store', dest='sequence_npy_file',\n","                    help='data file')\n","parser.add_argument('-data_params', action='store', dest='params_file',\n","                    help='params file')\n","parser.add_argument('-output', action='store',dest='output_file_prefix',\n","                    help='compressed file name')\n","\n","args, unknown = parser.parse_known_args()"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"rttWm8G0Q1kt","executionInfo":{"status":"ok","timestamp":1617351094477,"user_tz":-480,"elapsed":971,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["def strided_app(a, L, S):  # Window len = L, Stride len/stepsize = S\n","    nrows = ((a.size - L) // S) + 1\n","    n = a.strides[0]\n","    return np.lib.stride_tricks.as_strided(\n","        a, shape=(nrows, L), strides=(S * n, n), writeable=False)\n","    \n","def predict_lstm(X, y, y_original, timesteps, bs, alphabet_size, model_name, final_step=False):       \n","        if not final_step:\n","                num_iters = int((len(X)+timesteps)/bs)\n","                ind = np.array(range(bs))*num_iters\n","                \n","                # open compressed files and compress first few characters using\n","                # uniform distribution\n","                f = [open(args.temp_file_prefix+'.'+str(i),'wb') for i in range(bs)]\n","                bitout = [arithmeticcoding_fast.BitOutputStream(f[i]) for i in range(bs)]\n","                enc = [arithmeticcoding_fast.ArithmeticEncoder(32, bitout[i]) for i in range(bs)]\n","                prob = np.ones(alphabet_size)/alphabet_size\n","                cumul = np.zeros(alphabet_size+1, dtype = np.uint64)\n","                cumul[1:] = np.cumsum(prob*10000000 + 1)        \n","                for i in range(bs):\n","                        for j in range(min(timesteps, num_iters)):\n","                                enc[i].write(cumul, X[ind[i],j])\n","                cumul = np.zeros((bs, alphabet_size+1), dtype = np.uint64)\n","                for j in (range(num_iters - timesteps)):\n","                        x=torch.Tensor(X[ind,:])\n","                        x = x.reshape(-1,timesteps, input_size).to(device)\n","                        outputs = model(x)\n","                        prob=F.softmax(outputs).data.cpu().numpy()\n","                        cumul[:,1:] = np.cumsum(prob*10000000 + 1, axis = 1)\n","                        for i in range(bs):\n","                                enc[i].write(cumul[i,:], y_original[ind[i]])\n","                        ind = ind + 1\n","                # close files\n","                for i in range(bs):\n","                        enc[i].finish()\n","                        bitout[i].close()\n","                        f[i].close()            \n","        else:\n","                f = open(args.temp_file_prefix+'.last','wb')\n","                bitout = arithmeticcoding_fast.BitOutputStream(f)\n","                enc = arithmeticcoding_fast.ArithmeticEncoder(32, bitout)\n","                prob = np.ones(alphabet_size)/alphabet_size\n","                cumul = np.zeros(alphabet_size+1, dtype = np.uint64)\n","                cumul[1:] = np.cumsum(prob*10000000 + 1)        \n","\n","                for j in range(timesteps):\n","                        enc.write(cumul, X[0,j])\n","                for i in (range(len(X))):\n","                        x=torch.Tensor(X[i,:])\n","                        x = x.reshape(-1,timesteps, input_size).to(device)\n","                        outputs = model(x)\n","                        prob=F.softmax(outputs).data.cpu().numpy()\n","                        cumul[1:] = np.cumsum(prob*10000000 + 1)\n","                        enc.write(cumul, y_original[i][0])\n","                enc.finish()\n","                bitout.close()\n","                f.close()\n","        return\n","\n","\n","# variable length integer encoding http://www.codecodex.com/wiki/Variable-Length_Integers\n","def var_int_encode(byte_str_len, f):\n","        while True:\n","                this_byte = byte_str_len&127\n","                byte_str_len >>= 7\n","                if byte_str_len == 0:\n","                        f.write(struct.pack('B',this_byte))\n","                        break\n","                f.write(struct.pack('B',this_byte|128))\n","                byte_str_len -= 1"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"nHoMwGMkQ7fZ","executionInfo":{"status":"ok","timestamp":1617351097897,"user_tz":-480,"elapsed":870,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["args.sequence_npy_file=\"../data/processed_files/text8.npy\"\n","args.params_file=\"../data/processed_files/text8.param.json\"\n","\n","\n","args.model_weights_file=\"../data/trained_models/text8/lstm_weights\"\n","# args.model_weights_file=\"../data/trained_models/text8/lstm_pruned_weights\"\n","# args.model_weights_file=\"../data/trained_models/text8/lstm_quantization_weights\"\n","# args.model_weights_file=\"../data/trained_models/text8/lstm_quantization_pruned_weights\"\n","\n","\n","args.model_name=\"LSTM\"\n","\n","\n","args.output_file_prefix=\"../data/compressed/text8/lstm_weights.compressed\"\n","# args.output_file_prefix=\"../data/compressed/text8/lstm_pruned_weights.compressed\"\n","# args.output_file_prefix=\"../data/compressed/text8/lstm_quantization_weights.compressed\"\n","# args.output_file_prefix=\"../data/compressed/text8/lstm_quantization_pruned_weights.compressed\"\n","\n","\n","args.batch_size=1000"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"LqcGsl1eRKcx","executionInfo":{"status":"ok","timestamp":1617351100916,"user_tz":-480,"elapsed":1508,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# load the data\n","args.temp_dir = tempfile.mkdtemp()\n","args.temp_file_prefix = args.temp_dir + \"/compressed\"\n","np.random.seed(0)\n","series = np.load(args.sequence_npy_file)\n","series=series[0:100000]\n","series = series.reshape(-1, 1)\n","onehot_encoder = OneHotEncoder(sparse=False)\n","onehot_encoded = onehot_encoder.fit(series)\n","\n","batch_size = args.batch_size\n","timesteps = 64\n","\n","with open(args.params_file, 'r') as f:\n","        params = json.load(f)\n","\n","params['len_series'] = len(series)\n","params['bs'] = batch_size\n","params['timesteps'] = timesteps\n","\n","with open(args.output_file_prefix+'.params','w') as f:\n","        json.dump(params, f, indent=4)\n","\n","alphabet_size = len(params['id2char_dict'])\n","\n","series = series.reshape(-1)\n","data = strided_app(series, timesteps+1, 1)\n","\n","X = data[:, :-1]\n","Y_original = data[:, -1:]\n","Y = onehot_encoder.transform(Y_original)\n","\n","l = int(len(series)/batch_size)*batch_size"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"sw4asunFRkpu","executionInfo":{"status":"ok","timestamp":1617351115964,"user_tz":-480,"elapsed":835,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# Hyper Parameters\n","num_epochs=10            \n","input_size = 1   \n","# hidden_size = 64\n","hidden_size = 1024\n","num_layers = 1\n","num_classes = alphabet_size\n","lr = 0.01   \n","\n","\n","# Define LSTM model\n","class simpleLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(simpleLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True).to(device)\n","        self.fc = nn.Linear(hidden_size, num_classes).to(device)\n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        # forward propagate lstm\n","        out, (h_n, h_c) = self.lstm(x, (h0, c0))\n","\n","        # output\n","        out =self.fc(out[:, -1, :])\n","        return out\n","\n","model = simpleLSTM(input_size, hidden_size, num_layers, num_classes)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"3B8MpwIw_rL_","executionInfo":{"status":"ok","timestamp":1617351121732,"user_tz":-480,"elapsed":4286,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# unzip the compressed models\n","zip_path=\"../data/trained_models/text8/lstm_weights.zip\"\n","save_path=\"../data/trained_models/text8\"\n","with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","    zip_ref.extractall(save_path)\n","\n","# zip_path=\"../data/trained_models/text8/lstm_pruned_weights.zip\"\n","# save_path=\"../data/trained_models/text8\"\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(save_path)\n","\n","# zip_path=\"../data/trained_models/text8/lstm_quantization_weights.zip\"\n","# save_path=\"../data/trained_models/text8\"\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(save_path)\n","\n","# zip_path=\"../data/trained_models/text8/lstm_quantization_pruned_weights.zip\"\n","# save_path=\"../data/trained_models/text8\"\n","# with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","#     zip_ref.extractall(save_path)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KCNwMI12RpaZ","executionInfo":{"status":"ok","timestamp":1617351125401,"user_tz":-480,"elapsed":1185,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"a48d3ce3-61ae-4847-be31-871f84228ff2"},"source":["#load the model weights\n","model.load_state_dict(torch.load(args.model_weights_file))\n","\n","# # load the quantized model weights\n","# model = torch.quantization.quantize_dynamic(\n","#     model, {nn.LSTM, nn.Linear}, dtype=torch.qint8\n","# )\n","# model.load_state_dict(torch.load(args.model_weights_file))"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BeD7_5f7R2YY","executionInfo":{"status":"ok","timestamp":1617351289013,"user_tz":-480,"elapsed":162122,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"456520a0-3870-4fb9-ad68-f548ddcd9bdc"},"source":["# compress the data \n","predict_lstm(X, Y, Y_original, timesteps, batch_size, alphabet_size, args.model_name)\n","\n","if l < len(series)-timesteps:\n","        predict_lstm(X[l:,:], Y[l:,:], Y_original[l:], timesteps, 1, alphabet_size, args.model_name, final_step = True)\n","else:\n","        f = open(args.temp_file_prefix+'.last','wb')\n","        bitout = arithmeticcoding_fast.BitOutputStream(f)\n","        enc = arithmeticcoding_fast.ArithmeticEncoder(32, bitout) \n","        prob = np.ones(alphabet_size)/alphabet_size\n","        \n","        cumul = np.zeros(alphabet_size+1, dtype = np.uint64)\n","        cumul[1:] = np.cumsum(prob*10000000 + 1)        \n","        for j in range(l, len(series)):\n","                enc.write(cumul, series[j])\n","        enc.finish()\n","        bitout.close() \n","        f.close()\n","\n","# combine files into one file\n","f = open(args.output_file_prefix+'.combined','wb')\n","for i in range(batch_size):\n","        f_in = open(args.temp_file_prefix+'.'+str(i),'rb')\n","        byte_str = f_in.read()\n","        byte_str_len = len(byte_str)\n","        var_int_encode(byte_str_len, f)\n","        f.write(byte_str)\n","        f_in.close()\n","f_in = open(args.temp_file_prefix+'.last','rb')\n","byte_str = f_in.read()\n","byte_str_len = len(byte_str)\n","var_int_encode(byte_str_len, f)\n","f.write(byte_str)\n","f_in.close()\n","f.close()\n","shutil.rmtree(args.temp_dir)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8DOn4AaQRZC6"},"source":[""],"execution_count":null,"outputs":[]}]}