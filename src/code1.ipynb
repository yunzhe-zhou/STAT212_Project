{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code1.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wXlF4dbFLiTk","executionInfo":{"status":"ok","timestamp":1617608745779,"user_tz":-480,"elapsed":982,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["import os\n","os.getcwd()\n","os.chdir(\"drive/My Drive/STAT212/DeepZip_code/src\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJo3EIFrLqCW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617608747691,"user_tz":-480,"elapsed":1344,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"16f2c784-0c81-4532-8fa9-678d7e1b5134"},"source":["from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import torch.nn.utils.prune as prune\n","import torch.quantization\n","import copy \n","import os\n","import zipfile\n","import tempfile\n","import shutil\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.manual_seed(1)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f326c05a2f0>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"modH9c2fMRy9","executionInfo":{"status":"ok","timestamp":1617608749025,"user_tz":-480,"elapsed":799,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["file_path=\"../data/processed_files/text8_sub100000.npy\"\n","batch_size=128\n","time_steps= 64\n","\n","def strided_app(a, L, S):  # Window len = L, Stride len/stepsize = S\n","        nrows = ((a.size - L) // S) + 1\n","        n = a.strides[0]\n","        return np.lib.stride_tricks.as_strided(a, shape=(nrows, L), strides=(S * n, n), writeable=False)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"61nFwuOAVnWY","executionInfo":{"status":"ok","timestamp":1617608750731,"user_tz":-480,"elapsed":944,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# load the preprocessed data\n","series = np.load(file_path)\n","series = series.reshape(-1, 1)\n","\n","onehot_encoder = OneHotEncoder(sparse=False)\n","onehot_encoded = onehot_encoder.fit(series)\n","series = series.reshape(-1)\n","\n","data = strided_app(series, time_steps+1, 1)\n","l = int(len(data)/batch_size) * batch_size\n","\n","data = data[:l] \n","X = data[:, :-1]\n","Y = data[:, -1:].reshape([-1,])\n","Y_hot = onehot_encoder.transform(data[:, -1:])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHpei-0bMy_H","executionInfo":{"status":"ok","timestamp":1617608755500,"user_tz":-480,"elapsed":4167,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# Hyper Parameters\n","num_epochs=10           \n","input_size = 1   \n","hidden_size = 64\n","num_layers = 2\n","num_classes = Y_hot.shape[1]\n","lr = 0.01   \n","\n","\n","# Define LSTM model\n","class simpleLSTM(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n","        super(simpleLSTM, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True).to(device)\n","        self.fc = nn.Linear(hidden_size, num_classes).to(device)\n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n","\n","        # forward propagate lstm\n","        out, (h_n, h_c) = self.lstm(x, (h0, c0))\n","\n","        # output\n","        out =self.fc(out[:, -1, :])\n","        return out\n","\n","model = simpleLSTM(input_size, hidden_size, num_layers, num_classes)\n","\n","# loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"vp2OMWdRMzBY"},"source":["# load training data\n","train_data = TensorDataset(torch.Tensor(X),torch.Tensor(Y).long())\n","train_loader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True) \n","\n","# train\n","total_step = len(train_loader)\n","for epoch in range(num_epochs):\n","    for i, (x, y) in enumerate(train_loader):\n","        x = x.reshape(-1, time_steps, input_size).to(device)\n","        y = y.to(device)\n","\n","        # forward pass\n","        outputs = model(x)\n","        loss = criterion(outputs, y)\n","\n","        # backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 100 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtnnUrz-Nyyx","executionInfo":{"status":"ok","timestamp":1617608810636,"user_tz":-480,"elapsed":55124,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"f9d074f7-a035-4bae-9d18-e383fb056747"},"source":["# test accuary\n","test_data = TensorDataset(torch.Tensor(X),torch.Tensor(Y).long())\n","test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=True) \n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    for x, y in test_loader:\n","        x = x.reshape(-1, time_steps, input_size).to(device)\n","        y = y.to(device)\n","        outputs = model(x)\n","        prob=F.softmax(outputs)\n","        _, predicted = torch.max(prob, 1)\n","        total += y.size(0)\n","        correct += (predicted == y).sum().item()\n","\n","    print('Test Accuracy of the model on the 10000 test x: {} %'.format(100 * correct / total))"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  # This is added back by InteractiveShellApp.init_path()\n"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy of the model on the 10000 test x: 51.74579326923077 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"el8aP_kr5eOH","executionInfo":{"status":"ok","timestamp":1617608810637,"user_tz":-480,"elapsed":54154,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# save the original model\n","torch.save(model.state_dict(), \"../data/trained_models/text8/temptory/lstm_weights\")"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HE_GYDqNaI1","executionInfo":{"status":"ok","timestamp":1617608810638,"user_tz":-480,"elapsed":53372,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# copy a model0 for pruning\n","model0=copy.deepcopy(model)\n","\n","for name, module in model0.named_modules():\n","    # prune 20% of connections in all lstm layers\n","    if isinstance(module, torch.nn.LSTM):\n","        prune.l1_unstructured(module, name='weight_hh_l0', amount=0.2)\n","        prune.l1_unstructured(module, name='weight_ih_l0', amount=0.2)\n","    # prune 40% of connections in all linear layers\n","    elif isinstance(module, torch.nn.Linear):\n","        prune.l1_unstructured(module, name='weight', amount=0.4)\n","\n","for name, module in model0.named_modules():\n","    # prune 20% of connections in all lstm layers\n","    if isinstance(module, torch.nn.LSTM):\n","        prune.remove(module, 'weight_hh_l0')\n","        prune.remove(module, 'weight_ih_l0')\n","    # prune 40% of connections in all linear layers\n","    elif isinstance(module, torch.nn.Linear):\n","        prune.remove(module, 'weight')\n","\n","torch.save(model0.state_dict(), \"../data/trained_models/text8/temptory/lstm_pruned_weights\")"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"08e4wTcjNaLY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617608811870,"user_tz":-480,"elapsed":1226,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"677318af-ced0-4b9d-9c8c-e0b6d9531bf6"},"source":["# quantize the unpruned model\n","quantized_model = torch.quantization.quantize_dynamic(\n","    model.to('cpu'), {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",")\n","print(quantized_model)\n","\n","# quantize the pruned model\n","quantized_model0 = torch.quantization.quantize_dynamic(\n","    model0.to('cpu'), {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",")\n","print(quantized_model0)\n","\n","torch.save(quantized_model.state_dict(), \"../data/trained_models/text8/temptory/lstm_quantization_weights\")\n","torch.save(quantized_model0.state_dict(), \"../data/trained_models/text8/temptory/lstm_quantization_pruned_weights\")"],"execution_count":10,"outputs":[{"output_type":"stream","text":["simpleLSTM(\n","  (lstm): DynamicQuantizedLSTM(1, 64, num_layers=2, batch_first=True)\n","  (fc): DynamicQuantizedLinear(in_features=64, out_features=27, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n","simpleLSTM(\n","  (lstm): DynamicQuantizedLSTM(1, 64, num_layers=2, batch_first=True)\n","  (fc): DynamicQuantizedLinear(in_features=64, out_features=27, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E429fy6pBkoS","executionInfo":{"status":"ok","timestamp":1617608916760,"user_tz":-480,"elapsed":779,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"e0c853ca-84f5-4707-aca2-56ef569c7eb9"},"source":["# define a gzip function\n","def get_gzipped_model_size(file,path):\n","  # Returns size of gzipped model, in bytes.\n","  _, zipped_file = tempfile.mkstemp('.zip')\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(file)\n","  shutil.copy(zipped_file, path)\n","  return os.path.getsize(zipped_file)\n","\n","os.chdir(\"../data/trained_models/text8/temptory\")\n","file_path=\"lstm_weights\"\n","save_path=\"../lstm_weights.zip\"\n","print(\"Size of gzipped baseline model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_pruned_weights\"\n","save_path=\"../lstm_pruned_weights.zip\"\n","print(\"Size of gzipped pruned model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_quantization_weights\"\n","save_path=\"../lstm_quantization_weights.zip\"\n","print(\"Size of gzipped quantized baseline model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_quantization_pruned_weights\"\n","save_path=\"../lstm_quantization_pruned_weights.zip\"\n","print(\"Size of gzipped quantized and pruned model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Size of gzipped baseline model: 192.23 KB\n","Size of gzipped pruned model: 182.52 KB\n","Size of gzipped quantized baseline model: 44.95 KB\n","Size of gzipped quantized and pruned model: 44.42 KB\n"],"name":"stdout"}]}]}