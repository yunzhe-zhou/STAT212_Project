{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"code1_revise.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"13CJLc-ACdf60I75tnWDNTaxpCXwYVbdj","authorship_tag":"ABX9TyM5+il5TxG7k1Op/RZP2Cs5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"wXlF4dbFLiTk","executionInfo":{"status":"ok","timestamp":1617962979743,"user_tz":-480,"elapsed":1068,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["import os\n","os.getcwd()\n","os.chdir(\"drive/My Drive/STAT212/DeepZip_code/src\")"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"jJo3EIFrLqCW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617962980796,"user_tz":-480,"elapsed":2110,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"b8c16749-87e8-4ec5-b147-ccf1f73c5b82"},"source":["from sklearn.preprocessing import OneHotEncoder\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.utils.data import TensorDataset, DataLoader\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.functional as F\n","import torch.nn.utils.prune as prune\n","import torch.quantization\n","import copy \n","import os\n","import zipfile\n","import tempfile\n","import shutil\n","\n","# Device configuration\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","torch.manual_seed(1)"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7f7f50e6c250>"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"modH9c2fMRy9","executionInfo":{"status":"ok","timestamp":1617962980796,"user_tz":-480,"elapsed":2103,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["file_path=\"../data/processed_files/text8_sub2000000.npy\"\n","batch_size=128\n","time_steps= 64\n","\n","def strided_app(a, L, S):  # Window len = L, Stride len/stepsize = S\n","        nrows = ((a.size - L) // S) + 1\n","        n = a.strides[0]\n","        return np.lib.stride_tricks.as_strided(a, shape=(nrows, L), strides=(S * n, n), writeable=False)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"61nFwuOAVnWY","executionInfo":{"status":"ok","timestamp":1617962981938,"user_tz":-480,"elapsed":3241,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# load the preprocessed data\n","series = np.load(file_path)\n","series = series.reshape(-1, 1)\n","\n","onehot_encoder = OneHotEncoder(sparse=False)\n","onehot_encoded = onehot_encoder.fit(series)\n","series = series.reshape(-1)\n","\n","data = strided_app(series, time_steps+1, 1)\n","l = int(len(data)/batch_size) * batch_size\n","\n","data = data[:l] \n","X = data[:, :-1]\n","Y = data[:, -1:].reshape([-1,])\n","Y_hot = onehot_encoder.transform(data[:, -1:])"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"MmRiVQ4NTBYI","executionInfo":{"status":"ok","timestamp":1617962981939,"user_tz":-480,"elapsed":3239,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["class LSTM(nn.Module):\n","    def __init__(self, num_classes, hidden_size1=32, hidden_size2=32, num_layers=2):\n","        super(LSTM, self).__init__()\n","        self.hidden_size1 = hidden_size1\n","        self.hidden_size2 = hidden_size2\n","        self.num_layers = num_layers\n","        self.embedding= nn.Embedding(num_classes, 32).to(device)\n","        self.lstm = nn.LSTM(32, hidden_size1, num_layers, batch_first=True).to(device)\n","        self.fc1 = nn.Linear(hidden_size1, hidden_size2).to(device)\n","        self.fc2 = nn.Linear(hidden_size2, num_classes).to(device)\n","        \n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size1).to(device)\n","        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size1).to(device)\n","        \n","        out=self.embedding(x[:,:,0].long())\n","        out, (h_n, h_c) = self.lstm(out, (h0, c0))\n","        out =self.fc1(out[:, -1, :])\n","        out =self.fc2(nn.ReLU()(out))\n","\n","        return out\n","\n","\n","class GRU(nn.Module):\n","    def __init__(self, num_classes, hidden_size1=32, hidden_size2=32, num_layers=2):\n","        super(GRU, self).__init__()\n","        self.hidden_size1 = hidden_size1\n","        self.hidden_size2 = hidden_size2\n","        self.num_layers = num_layers\n","        self.embedding= nn.Embedding(num_classes, 32).to(device)\n","        self.lstm = nn.GRU(32, hidden_size1, num_layers, batch_first=True).to(device)\n","        self.fc1 = nn.Linear(hidden_size1, hidden_size2).to(device)\n","        self.fc2 = nn.Linear(hidden_size2, num_classes).to(device)\n","        \n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size1).to(device)\n","        \n","        out=self.embedding(x[:,:,0].long())\n","        out, _ = self.lstm(out, h0)\n","        out =self.fc1(out[:, -1, :])\n","        out =self.fc2(nn.ReLU()(out))\n","\n","        return out\n","\n","class biLSTM(nn.Module):\n","    def __init__(self, num_classes, hidden_size1=32, hidden_size2=32, num_layers=2):\n","        super(biLSTM, self).__init__()\n","        self.hidden_size1 = hidden_size1\n","        self.hidden_size2 = hidden_size2\n","        self.num_layers = num_layers\n","        self.embedding= nn.Embedding(num_classes, 32).to(device)\n","        self.lstm = nn.LSTM(32, hidden_size1, num_layers, batch_first=True,bidirectional=True).to(device)\n","        self.fc1 = nn.Linear(hidden_size1*2, hidden_size2*2).to(device)\n","        self.fc2 = nn.Linear(hidden_size2*2, num_classes).to(device)\n","        \n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size1).to(device)\n","        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size1).to(device)\n","        \n","        out=self.embedding(x[:,:,0].long())\n","        out, (h_n, h_c) = self.lstm(out, (h0, c0))\n","        out =self.fc1(out[:, -1, :])\n","        out =self.fc2(nn.ReLU()(out))\n","\n","        return out\n","        \n","class biGRU(nn.Module):\n","    def __init__(self, num_classes, hidden_size1=32, hidden_size2=32, num_layers=2):\n","        super(biGRU, self).__init__()\n","        self.hidden_size1 = hidden_size1\n","        self.hidden_size2 = hidden_size2\n","        self.num_layers = num_layers\n","        self.embedding= nn.Embedding(num_classes, 32).to(device)\n","        self.lstm = nn.GRU(32, hidden_size1, num_layers, batch_first=True,bidirectional=True).to(device)\n","        self.fc1 = nn.Linear(hidden_size1*2, hidden_size2*2).to(device)\n","        self.fc2 = nn.Linear(hidden_size2*2, num_classes).to(device)\n","        \n","\n","    def forward(self, x):\n","        # initialize\n","        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size1).to(device)\n","        \n","        out=self.embedding(x[:,:,0].long())\n","        out, _ = self.lstm(out, h0)\n","        out =self.fc1(out[:, -1, :])\n","        out =self.fc2(nn.ReLU()(out))\n","\n","        return out"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"PzrLmW9GTBaP","executionInfo":{"status":"ok","timestamp":1617962984315,"user_tz":-480,"elapsed":5611,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# Hyper Parameters\n","input_size = 1   \n","num_epochs=10        \n","hidden_size1 = 32\n","hidden_size2 = 32\n","num_layers = 2\n","num_classes = Y_hot.shape[1]\n","lr = 0.001 \n","\n","model = LSTM(num_classes,hidden_size1, hidden_size2, num_layers)\n","# model = GRU(num_classes,hidden_size1, hidden_size2, num_layers)\n","# model = biLSTM(num_classes,hidden_size1, hidden_size2, num_layers)\n","# model = biGRU(num_classes,hidden_size1, hidden_size2, num_layers)\n","\n","# loss and optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"vp2OMWdRMzBY"},"source":["# load training data\n","train_data = TensorDataset(torch.Tensor(X),torch.Tensor(Y).long())\n","train_loader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True) \n","test_data = TensorDataset(torch.Tensor(X),torch.Tensor(Y).long())\n","test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=True) \n","\n","# train\n","total_step = len(train_loader)\n","model_ls=[]\n","accuracy=[]\n","for epoch in range(num_epochs):\n","    for i, (x, y) in enumerate(train_loader):\n","        x = x.reshape(-1, time_steps, input_size).to(device)\n","        y = y.to(device)\n","\n","        # forward pass\n","        outputs = model(x)\n","        loss = criterion(outputs, y)\n","\n","        # backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        if i % 1000 == 0:\n","            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n","                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","            \n","            with torch.no_grad():\n","                correct = 0\n","                total = 0\n","                times=0\n","                for x, y in test_loader:\n","                    x = x.reshape(-1, time_steps, input_size).to(device)\n","                    y = y.to(device)\n","                    outputs = model(x)\n","                    prob=F.softmax(outputs)\n","                    _, predicted = torch.max(prob, 1)\n","                    total += y.size(0)\n","                    correct += (predicted == y).sum().item()\n","                    times=times+1\n","                    if times > 100:\n","                        break\n","\n","                print('Test Accuracy of the model on the 10000 test x: {} %'.format(100 * correct / total))\n","            model_ls.append(model)\n","            accuracy.append(100 * correct / total)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R4mQzZLq-7YB","executionInfo":{"status":"ok","timestamp":1617964015666,"user_tz":-480,"elapsed":1036953,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["model=model_ls[np.argmax(accuracy)]"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtnnUrz-Nyyx","executionInfo":{"status":"ok","timestamp":1617964016003,"user_tz":-480,"elapsed":1037286,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"98504754-a3d8-49ce-c834-638a5c1a3aa9"},"source":["# test accuary\n","test_data = TensorDataset(torch.Tensor(X),torch.Tensor(Y).long())\n","test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=True) \n","with torch.no_grad():\n","    correct = 0\n","    total = 0\n","    times=0\n","    for x, y in test_loader:\n","        x = x.reshape(-1, time_steps, input_size).to(device)\n","        y = y.to(device)\n","        outputs = model(x)\n","        prob=F.softmax(outputs)\n","        _, predicted = torch.max(prob, 1)\n","        total += y.size(0)\n","        correct += (predicted == y).sum().item()\n","        times=times+1\n","        if times > 100:\n","            break\n","\n","    print('Test Accuracy of the model on the 10000 test x: {} %'.format(100 * correct / total))"],"execution_count":9,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["Test Accuracy of the model on the 10000 test x: 53.44987623762376 %\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"el8aP_kr5eOH","executionInfo":{"status":"ok","timestamp":1617964016005,"user_tz":-480,"elapsed":1037283,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# save the original model\n","torch.save(model.state_dict(), \"../data/trained_models/text8/temptory/lstm_weights\")"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"6HE_GYDqNaI1","executionInfo":{"status":"ok","timestamp":1617964016373,"user_tz":-480,"elapsed":1037648,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# copy a model0 for pruning\n","model0=copy.deepcopy(model)\n","\n","for name, module in model0.named_modules():\n","    # prune 20% of connections in all lstm layers\n","    if isinstance(module, torch.nn.LSTM):\n","        prune.l1_unstructured(module, name='weight_hh_l0', amount=0.2)\n","        prune.l1_unstructured(module, name='weight_ih_l0', amount=0.2)\n","    # prune 40% of connections in all linear layers\n","    elif isinstance(module, torch.nn.Linear):\n","        prune.l1_unstructured(module, name='weight', amount=0.4)\n","\n","for name, module in model0.named_modules():\n","    # prune 20% of connections in all lstm layers\n","    if isinstance(module, torch.nn.LSTM):\n","        prune.remove(module, 'weight_hh_l0')\n","        prune.remove(module, 'weight_ih_l0')\n","    # prune 40% of connections in all linear layers\n","    elif isinstance(module, torch.nn.Linear):\n","        prune.remove(module, 'weight')\n","\n","torch.save(model0.state_dict(), \"../data/trained_models/text8/temptory/lstm_pruned_weights\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"08e4wTcjNaLY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617964016376,"user_tz":-480,"elapsed":1037647,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"de3df5f6-f7a8-4a37-8b97-8f8bb59b5861"},"source":["# quantize the unpruned model\n","quantized_model = torch.quantization.quantize_dynamic(\n","    model.to('cpu'), {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",")\n","print(quantized_model)\n","\n","# quantize the pruned model\n","quantized_model0 = torch.quantization.quantize_dynamic(\n","    model0.to('cpu'), {nn.LSTM, nn.Linear}, dtype=torch.qint8\n",")\n","print(quantized_model0)\n","\n","torch.save(quantized_model.state_dict(), \"../data/trained_models/text8/temptory/lstm_quantization_weights\")\n","torch.save(quantized_model0.state_dict(), \"../data/trained_models/text8/temptory/lstm_quantization_pruned_weights\")"],"execution_count":12,"outputs":[{"output_type":"stream","text":["LSTM(\n","  (embedding): Embedding(27, 32)\n","  (lstm): DynamicQuantizedLSTM(32, 32, num_layers=2, batch_first=True)\n","  (fc1): DynamicQuantizedLinear(in_features=32, out_features=32, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","  (fc2): DynamicQuantizedLinear(in_features=32, out_features=27, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n","LSTM(\n","  (embedding): Embedding(27, 32)\n","  (lstm): DynamicQuantizedLSTM(32, 32, num_layers=2, batch_first=True)\n","  (fc1): DynamicQuantizedLinear(in_features=32, out_features=32, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n","  (fc2): DynamicQuantizedLinear(in_features=32, out_features=27, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tSYTYPBTgAmw","executionInfo":{"status":"ok","timestamp":1617964016378,"user_tz":-480,"elapsed":1037644,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":["# define a gzip function\n","def get_gzipped_model_size(file,path):\n","  # Returns size of gzipped model, in bytes.\n","  _, zipped_file = tempfile.mkstemp('.zip')\n","  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n","    f.write(file)\n","  shutil.copy(zipped_file, path)\n","  return os.path.getsize(zipped_file)\n","\n","os.chdir(\"../data/trained_models/text8/temptory\")"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E429fy6pBkoS","executionInfo":{"status":"ok","timestamp":1617964016381,"user_tz":-480,"elapsed":1037644,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}},"outputId":"30a18ba7-6512-4bc2-9720-5d7df45904a0"},"source":["file_path=\"lstm_weights\"\n","save_path=\"../lstm_weights.zip\"\n","print(\"Size of gzipped baseline model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_pruned_weights\"\n","save_path=\"../lstm_pruned_weights.zip\"\n","print(\"Size of gzipped pruned model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_quantization_weights\"\n","save_path=\"../lstm_quantization_weights.zip\"\n","print(\"Size of gzipped quantized baseline model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","file_path=\"lstm_quantization_pruned_weights\"\n","save_path=\"../lstm_quantization_pruned_weights.zip\"\n","print(\"Size of gzipped quantized and pruned model: %.2f KB\" % (get_gzipped_model_size(file_path,save_path)/1024))\n","\n","os.chdir(\"../../../../src\")"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Size of gzipped baseline model: 73.02 KB\n","Size of gzipped pruned model: 67.45 KB\n","Size of gzipped quantized baseline model: 23.83 KB\n","Size of gzipped quantized and pruned model: 23.13 KB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lbw39ngZ60jo","executionInfo":{"status":"ok","timestamp":1617964016383,"user_tz":-480,"elapsed":1037642,"user":{"displayName":"LAI MZ","photoUrl":"","userId":"15718361365988174990"}}},"source":[""],"execution_count":14,"outputs":[]}]}